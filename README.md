# Huffman-Coding-Parallel

Data compression is an important process to allow for memory savings. There are two main types of compression algorithms lossless and lossy. Lossless algorithms ensure that there is no loss of data during the encoding and decoding of data. Lossy can result in lost data after encoding and decoding data. We will be exploring the parallelization of Huffman coding a popular lossless compression algorithm. The goal of this project is to improve the speed of encoding or decoding data using Huffman coding. 

<hr>

In this project, we implement the Huffman Coding algorithm with pthreads.
The linear nature of the algorithm proved to make the process of parallelization difficult.

The code is set up find the frequency of each character in parallel but the act of encoding and decoding are performed in series.

This leads to minor time gains in the compression/decompression process as a majority of the work cannot be parallel.
If we where to do the project again spending sometime to find algorithms that might better be parallelized would be beneficial.

## Source code

* `huffman.c` - Huffman Encoding implemented in C with Pthreads.
* `setup.sh`- A script that creates a 'Data' folder and populates it with files filled with random data.
* `run.sh` - A script the compiles the executable, encodes then decodes files, then compares the original and decompressed files.
* `cleanup.sh` - A script that deletes the executable and all folders and files generated by the `run.sh` script.

## Usage

Run `setup.sh`

    $ ./setup.sh

Run `run.sh`

    $ ./run.sh

Run `cleanup.sh`

    $ ./cleanup.sh

<hr>

## Credits

Source code for [`huffman.c`](huffman.c) is modified from [gyaikhom](https://github.com/gyaikhom/huffman)
